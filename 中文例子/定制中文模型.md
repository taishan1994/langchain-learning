```python
# 使用langchain加载中文模型
# 继承LLM，并重写_llm_type、_call、_identifying_params方法
import json
from transformers import AutoModelForCausalLM, AutoTokenizer

class ModelLoader:
  def __init__(self, model_name_or_path):
    self.model_name_or_path = model_name_or_path
    self.model, self.tokenizer = self.load()
  
  def load(self):
    tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained("openbmb/cpm-bee-1b", trust_remote_code=True).cuda()
    return model, tokenizer

modelLoader = ModelLoader("openbmb/cpm-bee-1b")

from typing import Any, List, Mapping, Optional
from langchain.llms.base import LLM
class CpmBee(LLM):
  @property
  def _llm_type(self) -> str:
    return "cpm-bee-1B"

  def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
    print(prompt)
    prompt = json.loads(prompt)
    tokenizer = modelLoader.tokenizer
    model = modelLoader.model
    result = model.generate(prompt, tokenizer)
    if len(result) == 1:
      return result[0]["<ans>"]
    return "对不起，我没有理解你的意思"
  
  @property
  def _identifying_params(self) -> Mapping[str, Any]:
    params_dict = {
      "test": "这里是参数字典",
    }
    return params_dict

prompt = {"input": "今天天气真不错", "question": "今天天气怎么样？", "<ans>": ""}
cpmBee = CpmBee()

print(cpmBee)

print(cpmBee(json.dumps(prompt, ensure_ascii=False)))

"""
CpmBee
Params: {'test': '这里是参数字典'}
{"input": "今天天气真不错", "question": "今天天气怎么样？", "<ans>": ""}
好
"""
```

